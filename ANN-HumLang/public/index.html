<!DOCTYPE html>
<html lang="en-US">

<head>
	<meta name="generator" content="Hugo 0.124.1">
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://ANN-HumLang.github.io/images/favicon.png" />
<title>Using Artificial Neural Networks for Studying Human Language Learning and Processing</title>
<meta name="title" content="Using Artificial Neural Networks for Studying Human Language Learning and Processing" />
<meta name="description" content="Workshop organized at Institute for Logic, Language, and Computation, University of Amsterdam." />
<meta name="keywords" content="" />






  
  <meta property="og:title" content="" />
<meta property="og:description" content="Workshop organized at Institute for Logic, Language, and Computation, University of Amsterdam." />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://ANN-HumLang.github.io/" /><meta property="og:image" content="https://ANN-HumLang.github.io/images/share.webp" /><meta property="og:site_name" content="Using Artificial Neural Networks for Studying Human Language Learning and Processing" />


  
  <meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://ANN-HumLang.github.io/images/share.webp" /><meta name="twitter:title" content=""/>
<meta name="twitter:description" content="Workshop organized at Institute for Logic, Language, and Computation, University of Amsterdam."/>
      <meta name="twitter:site" content="@mariannedhk"/>


  
  <meta itemprop="name" content="">
<meta itemprop="description" content="Workshop organized at Institute for Logic, Language, and Computation, University of Amsterdam.">

<meta name="referrer" content="no-referrer-when-downgrade" />

  
  <link href="/herman-light.min.css" rel="stylesheet">

  

  

  <link rel="alternate" type="application/rss+xml" href="https://ANN-HumLang.github.io/index.xml" title="Using Artificial Neural Networks for Studying Human Language Learning and Processing" />
  
</head>

<body>
  <header><script defer language="javascript" type="text/javascript" src="https://ANN-HumLang.github.io/js/jquery.min.js"></script>
<script defer language="javascript" type="text/javascript" src="https://ANN-HumLang.github.io/js/table.js"></script>

<a class="skip-link" href="#main-content">Skip to main content</a>
<div class="flex-container">
    <div class="flex-item-left">
        <img src="/images/ANN-HumLang-logo.svg">
    </div>
    <div class="flex-item-center"></div>
    <div class="flex-item-right">
        <a href="/" class="title">
            <h1>Using Artificial Neural Networks for Studying Human Language Learning and Processing</h1>
        </a>
    </div>
</div>

</header>
  <main id="main-content">

<h3 id="workshop-10-12-june-2024">Workshop (10-12 June, 2024)</h3>
<p>Artificial Neural Networks (ANNs) have proven to be powerful learning devices for language-related tasks, as demonstrated by recent progress in artificial intelligence driven by large, Transformer-based language models. But how can ANNs inform us about <em>human</em> language learning and processing? Our three-day workshop brings together researchers working on cognitively motivated and linguistic questions in studying the language processing mechanisms and learning trajectories of ANNs.</p>
<p>For the first two days of the programme, we hope to stimulate discussion on the workshop theme through contributed presentations from our workshop participants and keynote speakers. The final day is focussed on active interactions and collaboration between participants, through small-scale tutorials and joint group work on a collaborative task. See our provisional <a href="/workshop/#programme">programme</a> below for more information and currently confirmed participants!</p>
<h4 id="registration">Registration</h4>
<p><em><strong>Registration is now closed</strong></em>, and we have reached our maximum capacity for in-person participation. We have opened a 
<a href="https://forms.gle/6yn1ZRv7jf6pAVyE6"><button><b>wait list registration form</b></button></a> to sign up for the wait list. Please note that spaces may only become available on very short notice before the workshop.<br>
<em><strong>Streaming</strong></em> Items marked with 
<i class="fa-solid fa-video fa-sm"></i> on our 
<a href="#programme">programme</a> will be streamed via Zoom. Please leave your e-mail address in this 
<a href="https://forms.gle/ntAomXz2mYUMQXpY8"><button><b>streaming link form</b></button></a> if you would like to receive the link!</p>
<h4 id="organizers">Organizers</h4>
<p>Tamar Johnson (<a href="mailto:t.johnson@uva.nl">t.johnson@uva.nl</a>)<br>
Marianne de Heer Kloots (<a href="mailto:m.l.s.deheerkloots@uva.nl">m.l.s.deheerkloots@uva.nl</a>)</p>
<h4 id="venue">Venue</h4>
<p>Institute for Logic, Language and Computation<br>
SustainaLab event space, Amsterdam Science Park campus, University of Amsterdam</p>
<h4 id="keynote-speakers">Keynote speakers:</h4>
<p><a href="https://www.cs.rug.nl/~bisazza/">Arianna Bisazza</a> (University of Groningen)<br>
<details>
    <summary><em>Can modern Language Models be truly polyglot? Language learnability and inequalities in NLP</em></summary>
    <p>Despite their impressive advances, modern Language Models (LMs) are still far from reaching language equality, i.e. comparable performance in all languages.
The uneven amount of data available in different languages is often recognized as the main culprit. However, another obstacle to language equality is posed by the observation that some languages are intrinsically more difficult to model than others by modern LM architectures, even when training data size is controlled for.</p>
<p>In this talk, I will present evidence supporting this observation, coming from different tasks and different evaluation methodologies (e.g. using natural versus synthetic languages).
I will then argue for the usefulness of artificial languages to unravel the complex interplay between language properties and learnability by neural networks.
Finally, I will provide an outlook of my upcoming project aimed at improving language modeling for (low-resource) morphologically rich languages, taking inspiration from child language acquisition.</p>

</details></p>
<p><a href="https://evaportelance.github.io/">Eva Portelance</a> (Mila; HEC Montréal)<br>
<details>
    <summary><em>What neural networks can teach us about how we learn language</em></summary>
    <p>How can modern neural networks like large language models be useful to the field of language acquisition, and more broadly cognitive science, if they are not a priori designed to be cognitive models? As developments towards natural language understanding and generation have improved leaps and bounds, with models like GPT-4, the question of how they can inform our understanding of human language acquisition has re-emerged. This talk address how AI models as objects of study can indeed be useful tools for understanding how humans learn language. It will present three approaches for studying human learning behaviour using different types of neural networks and experimental designs, each illustrated through a specific case study.</p>
<p>Understanding how humans learn is an important problem for cognitive science and a window into how our minds work. Additionally, human learning is in many ways the most efficient and effective algorithm there is for learning language; understanding how humans learn can help us design better AI models in the future.</p>

</details></p>
<p><a href="https://wilcoxeg.github.io/">Ethan Wilcox</a> (ETH Zürich)<br>
<details>
    <summary><em>Using artificial neural networks to study human language processing: Two case studies and a warning</em></summary>
    Neural network language models are pure prediction engines, they have no communicative intent, and they do not learn language through social interactions. Despite this, I argue that they can be used to study human language processing, in particular, to empirically evaluate theories that are based on probability distributions over words. In the first half of this talk, I discuss two case studies in this vein, focusing on psycholinguistic theories of incremental processing, as well as regressions, or backward saccades between words. In the second half of the talk, I take a step back and discuss the impact of scaling for the usefulness of ANNs in psycholinguistics research. Scaling is the trend toward producing ever-larger models, both in terms of parameter counts and in terms of the amount of data they are trained on. While largely beneficial to performance on downstream benchmarking tasks, scaling has several downsides for computational psycholinguistics. I will discuss the scientific and practical challenges presented by scaling for neural network modeling, as well as the benefits that would result from human-scale language modeling research.
</details></p>
<h4 id="programme">Programme</h4>
<p>We have some pending timeslot shifts for our Tuesday and Wednesday schedule; please keep checking this webpage for the most up-to-date schedule!</p>


<script src="https://kit.fontawesome.com/2502d9ad4b.js" crossorigin="anonymous"></script>
<div class="wrapper">
<table border="0">
  <tr  class="header">
      <th colspan="2"><span>▾</span> Monday June 10th: <br>First day of keynote, talks and posters</th>
  </tr>
  <tr>
    <td>13.30 - 14.00</td>
    <td>
    Walk-in & Registration
    </td>
  </tr>
  <tr>
    <td>14.00 - 14.15</td>
    <td>
    Opening
    </td>
  </tr>
  <tr>
    <td>14.15 - 15.15 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Keynote lecture</b> by <a href="https://www.cs.rug.nl/~bisazza/">Arianna Bisazza</a> (University of Groningen):
    <br>
    <i>Can modern Language Models be truly polyglot? Language learnability and inequalities in NLP</i>
    </td>
  </tr>
  <tr>
    <td>15.15 - 15.45 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Talk</b> by <a href="https://sites.google.com/view/tessa-verhoef/home">Tessa Verhoef</a> (Leiden University):
    <br>
    <i>The emergence of language universals in neural agents and vision-and-language models</i>
    </td>
  </tr>
  <tr>
    <td>15.45 - 16.15 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Talk</b> by <a href="https://lgalke.github.io/">Lukas Galke</a> (Max Planck Institute for Psycholinguistics):
    <br>
    <i>Emergent communication and learning pressures in language models</i> 
    </td>
  </tr>
  <tr>
    <td>16.15 - 16.30</td>
    <td>
    Break
    </td>
  </tr>
  <tr>
    <td>16.30 - 18.00</td>
    <td>
    <b>Poster session</b> (see <a href="#list-of-posters">list of posters</a>)
    </td>
  </tr>
  <tr>
    <td>19.00 - 21.00</td>
    <td>
    Workshop dinner
    </td>
  </tr>
  <tr class="header">
    <th colspan="2"><span>▾</span> Tuesday June 11th: <br>Second day of keynotes, talks and discussions</th>
  </tr>
  <tr>
    <td>09.30 - 10.30 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Keynote lecture</b> by <a href="https://evaportelance.github.io/">Eva Portelance</a> (Mila; HEC Montréal):<br>
    <i>What neural networks can teach us about how we learn language</i>
    </td>
  </tr>
  <tr style="font-size:90%;font-weight:bold;background-color:rgba(0, 180, 157, 0.1)">
  <td colspan="2">Session on language learning</td>
  </tr>
  <tr class="session">
    <td>10.30 - 11.00 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Talk</b> by <a href="https://rgalhama.github.io/">Raquel G. Alhama</a> (University of Amsterdam):
    <br>
    <i>The Development of a Syntactic Category: Modeling Determiner Productivity in English-speaking Children</i>
    </td>
  </tr>
  <tr class="session">
    <td>11.00 - 11.30 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Talk</b> by <a href="https://mahowak.github.io/">Kyle Mahowald</a> (University of Texas at Austin):
    <br>
    <i>ANNs and AANNs: Linguistic Insights from Language Models</i>
    </td>
  </tr>
  <tr class="session">
    <td>11.30 - 11.45</td>
    <td>
    Break
    </td>
  </tr>
  <tr class="session">
    <td>11.45 - 12.15</td>
    <td>
    <b>Talk</b> by <a href="https://yevgen.web.rug.nl/">Yevgen Matusevych</a> (University of Groningen):
    <br>
    <i>Mutual exclusivity bias in visually grounded speech models</i>
    </td>
  </tr>
  <tr class="session">
    <td>12.15 - 12.45 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Discussion</b> on <i>using ANNs in modelling language learning</i>
    <br>
    Moderator: <a href="https://staff.fnwi.uva.nl/w.zuidema/">Jelle Zuidema</a> (University of Amsterdam)
    </td>
  </tr>
  </tr>
  <tr>
    <td>12.45 - 14.00</td>
    <td>Lunch</td>
  </tr>
  <tr>
    <td>14.00 - 15.00 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Keynote lecture</b> by <a href="https://wilcoxeg.github.io/">Ethan Wilcox</a> (ETH Zürich):
    <br>
    <i>Using artificial neural networks to study human language processing: Two case studies and a warning</i>
    </td>
  </tr>
  <tr style="font-size:90%;font-weight:bold;background-color:rgba(0, 180, 157, 0.1)">
  <td colspan="2">Session on language processing</td>
  </tr>
  <tr class="session">
    <td>15.00 - 15.30</td>
    <td>
    <b>Talk</b> by <a href="https://iwinther.github.io/">Irene Winther</a> (University of Edinburgh):
    <br>
    <i>Cumulative frequency can explain cognate facilitation in language models</i>
    </td>
  </tr>
  <tr class="session">
    <td>15.30 - 16.00 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Talk</b> by <a href="https://scholar.google.nl/citations?user=hC9ygKAAAAAJ&hl=en&oi=ao">Pierre Orhan</a> (École Normale Supérieure):
    <br>
    <i>Algebraic structures emerge from the self-supervised learning of natural sounds</i>
    </td>
  </tr>
  <tr class="session">
    <td>16.00 - 16.15</td>
    <td>
    Break
    </td>
  </tr>
  <tr class="session">
    <td>16.15 - 16.45 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Position statements</b> by <a href="https://michaheilbron.github.io/">Micha Heilbron</a> (University of Amsterdam) and <a href="http://www.stefanfrank.info/">Stefan Frank</a> (Radboud University Nijmegen)
    </td>
  </tr>
  <tr class="session">
    <td>16.45 - 17.15 <br><i class="fa-solid fa-video fa-sm"></i></td>
    <td>
    <b>Discussion</b> on <i>using ANNs in modelling language processing</i><br>
    Moderator: <a href="https://staff.fnwi.uva.nl/r.fernandezrovira/">Raquel Fernández</a> (University of Amsterdam)
    </td>
  </tr>
  <tr>
    <td>17.15 - 17.30</td>
    <td>
    Closing
    </td>
  </tr>
<tr class="header">
    <th colspan="2"><span>▾</span> Wednesday June 12th: <br>Interactions on learning trajectories in smaller- and larger-scale models</th>
</tr>
<tr>
    <td>09.30 - 09.45</td>
    <td>
    Introduction to the tutorials and collaborative tasks
    </td>
  </tr>
<tr>
    <td>09.45 - 10.30</td>
    <td>
    <b>First tutorial</b> by <a href="https://hconklin.com/">Henry Conklin</a> (University of Edinburgh): <br><i>Language learning as regularization: A non-parametric probing method for studying the emergence of structured representations over model training</i>
    </td>
  </tr>
<tr>
    <td>10.30 - 11.15</td>
    <td>
    <b>Second tutorial</b> by <a href="https://odvanderwal.nl/">Oskar van der Wal</a> & <a href="https://mdhk.net/">Marianne de Heer Kloots</a> (University of Amsterdam): <br><i>What's in a developmental phase? Training dynamics & Behavioural characterizations of grammar learning</i>
    </td>
  </tr>
<tr>
    <td>11.15 - 12.00</td>
    <td>
    Split up in groups & brainstorm
    </td>
  </tr>
<tr>
    <td>12.00 - 13.00</td>
    <td>
    Lunch
    </td>
  </tr>
<tr>
    <td>13.00 - 16.00</td>
    <td>
    Group work on collaborative tasks
    </td>
  </tr>
<tr>
    <td>16.00 - 17.30</td>
    <td>
    Discussion of findings
    </td>
  </tr>
<tr>
    <td>17.30</td>
    <td>
    Drinks
    </td>
  </tr>
</table>
</div>

<h4 id="list-of-posters">List of posters</h4>
<p>(this list is growing while registration is still open!)</p>
<ul>
<li><a href="https://gacarter.github.io/">Georgia Carter</a> (University of Edinburgh)<br>
<em>Predicting long context effects using surprisal</em></li>
<li><a href="https://axtimhaus.eu/">Victor Zimmermann</a> (Göttingen University)<br>
<em>Compositional phrase embeddings from latent Tree-LSTM representations</em></li>
<li><a href="https://www.ru.nl/en/people/suijkerbuijk-m">Michelle Suijkerbuijk</a> (Radboud University)<br>
<em>How (not) to test the syntactic knowledge in artificial neural networks: the case of island constraints</em></li>
<li><a href="https://hannamw.github.io/">Michael Hanna</a> (University of Amsterdam)<br>
<em>Building Mechanistic Bridges Between Biological and Artificial Neural Networks</em></li>
<li><a href="https://tianaidong.github.io/">Dota Dong</a> (Max Planck Institute for Psycholinguistics)<br>
<em>Multimodal Video Transformers Partially Align with Multimodal Grounding and Compositionality in the Brain</em></li>
<li><a href="https://www.linkedin.com/in/jos%C3%A9phine-raugel-738283134/">Joséphine Raugel</a> (École Normale Supérieure, Meta AI)<br>
<em>Decoding of Hierarchical Inference in the Human Brain during Speech Processing with Large Language Models</em></li>
<li><a href="https://scholar.google.com/citations?user=cpOrbSoAAAAJ&hl=en">Shangmin Guo</a> (University of Edinburgh)<br>
<em>Cultural evolution in the age of generative AI</em></li>
<li><a href="https://www.universiteitleiden.nl/en/staffmembers/tom-kouwenhoven#tab-1">Tom Kouwenhoven</a> (Leiden University)<br>
<em>The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication</em></li>
<li><a href="https://jumelet.ai/">Jaap Jumelet</a> (University of Amsterdam)<br>
<em>Do Language Models Exhibit Human-like Structural Priming Effects?</em></li>
<li><a href="https://hconklin.com/">Henry Conklin</a> (University of Edinburgh)<br>
<em>Representations as Language: An Information Theoretic Approach to Interpretability</em></li>
<li><a href="https://scholar.google.com/citations?user=GrYhyIQAAAAJ&hl=en">Polina Tsvilodub</a> (University of Tübingen)<br>
<em>Models of pragmatic language use with scaffolded LLMs</em></li>
<li><a href="https://www.linkedin.com/in/torrey-snyder-054956214/">Torrey Snyder</a> (University of Amsterdam)<br>
<em>Encoding Semantic Scene Descriptions: Cross-Modal Representations from Language to Vision</em></li>
<li><a href="https://www.linkedin.com/in/nitya-shah-320834267/">Nitya Shah</a> (University of Amsterdam)<br>
<em>Social Reasoning (Theory of Mind) in Language-and-Vision Models and Humans</em></li>
<li><a href="https://www.uva.nl/en/profile/b/r/m.m.brucklacher/m.m.brucklacher.html">Matthias Brucklacher</a> (University of Amsterdam)<br>
<em>Prediction as a mechanism for cognitive representation learning</em></li>
<li><a href="https://www.uva.nl/profiel/b/l/j.bloem/j.bloem.html">Jelke Bloem</a> (University of Amsterdam)<br>
<em>Using Collostructional Analysis to evaluate BERT&rsquo;s representation of linguistic constructions</em></li>
<li><a href="https://www.linkedin.com/in/thi-thao-anh-dang/">Dang Thi Thao Anh</a> (Radboud University)<br>
<em>Harnessing Cross-lingual Morphological Generalization Abilities in Large Language Models with a Multilingual Wug Test</em></li>
</ul>
<h4 id="acknowledgements">Acknowledgements</h4>
<p>This workshop is supported by and organized as part of the <em>Language in Interaction</em> consortium (NWO Gravitation Grant 024.001.006). We are also very thankful to the SustainaLab for lending us their space, and to Jelle Zuidema and the ILLC office for organizational advice and support!</p>


<div class="flex-container">
    <div class="flex-item-left">
        <a href="https://www.dcc.ru.nl/languageininteraction/"><img src="/images/LiI_Logo_450px.jpg" width=300></img></a>
    </div>
    <div class="flex-item-center"></div>
    <div class="flex-item-right">
        <a href="https://sustainalab.nl/"><img src="https://www.sustainalab.nl/wp-content/uploads/2023/11/SustainaLab_Logo_RGB.png" width=150></img></a>
    </div>
</div>




  </main>
  <footer><small>
    Tamar Johnson &amp; Marianne de Heer Kloots :: <b>ANN-HumLang</b> 
    <a href="/workshop/">Workshop</a> /
    
    <a href="/reading-group-archive/">Reading group archive</a> /
    

    
</small></footer>

    
</body>

</html>
