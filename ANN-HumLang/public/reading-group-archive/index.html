<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://ANN-HumLang.github.io/images/favicon.png" />
<title>Reading group archive | Using Artificial Neural Networks for Studying Human Language Learning and Processing</title>
<meta name="title" content="Reading group archive" />
<meta name="description" content="In the 2023 Spring Semester we organized a reading group at the ILLC, bringing together formal semanticists and computational linguists working at our institute to discuss the use of Artificial Neural Networks in modelling human language learning and processing. Below is an archive of the papers we read.
Feel free to keep suggesting papers in our sheet!
April 3rd, 2023 Li, J., Yu, L., &amp; Ettinger, A. (2022). Counterfactual reasoning: Do language models need world knowledge for causal inference?" />
<meta name="keywords" content="" />






  
  <meta property="og:title" content="Reading group archive" />
<meta property="og:description" content="In the 2023 Spring Semester we organized a reading group at the ILLC, bringing together formal semanticists and computational linguists working at our institute to discuss the use of Artificial Neural Networks in modelling human language learning and processing. Below is an archive of the papers we read.
Feel free to keep suggesting papers in our sheet!
April 3rd, 2023 Li, J., Yu, L., &amp; Ettinger, A. (2022). Counterfactual reasoning: Do language models need world knowledge for causal inference?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ANN-HumLang.github.io/reading-group-archive/" /><meta property="og:image" content="https://ANN-HumLang.github.io/images/share.webp" /><meta property="article:section" content="" />

<meta property="og:site_name" content="Using Artificial Neural Networks for Studying Human Language Learning and Processing" />


  
  <meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://ANN-HumLang.github.io/images/share.webp" /><meta name="twitter:title" content="Reading group archive"/>
<meta name="twitter:description" content="In the 2023 Spring Semester we organized a reading group at the ILLC, bringing together formal semanticists and computational linguists working at our institute to discuss the use of Artificial Neural Networks in modelling human language learning and processing. Below is an archive of the papers we read.
Feel free to keep suggesting papers in our sheet!
April 3rd, 2023 Li, J., Yu, L., &amp; Ettinger, A. (2022). Counterfactual reasoning: Do language models need world knowledge for causal inference?"/>
      <meta name="twitter:site" content="@mariannedhk"/>


  
  <meta itemprop="name" content="Reading group archive">
<meta itemprop="description" content="In the 2023 Spring Semester we organized a reading group at the ILLC, bringing together formal semanticists and computational linguists working at our institute to discuss the use of Artificial Neural Networks in modelling human language learning and processing. Below is an archive of the papers we read.
Feel free to keep suggesting papers in our sheet!
April 3rd, 2023 Li, J., Yu, L., &amp; Ettinger, A. (2022). Counterfactual reasoning: Do language models need world knowledge for causal inference?">

<meta itemprop="wordCount" content="490"><meta itemprop="image" content="https://ANN-HumLang.github.io/images/share.webp" />
<meta itemprop="keywords" content="" />

<meta name="referrer" content="no-referrer-when-downgrade" />

  
  <link href="/herman-light.min.css" rel="stylesheet">

  

  

  
</head>

<body>
  <header><script defer language="javascript" type="text/javascript" src="https://ANN-HumLang.github.io/js/jquery.min.js"></script>
<script defer language="javascript" type="text/javascript" src="https://ANN-HumLang.github.io/js/table.js"></script>

<a class="skip-link" href="#main-content">Skip to main content</a>
<div class="flex-container">
    <div class="flex-item-left">
        <img src="/images/ANN-HumLang-logo.svg">
    </div>
    <div class="flex-item-center"></div>
    <div class="flex-item-right">
        <a href="/" class="title">
            <h1>Using Artificial Neural Networks for Studying Human Language Learning and Processing</h1>
        </a>
    </div>
</div>

</header>
  <main id="main-content">


<content>
    <p>In the 2023 Spring Semester we organized a reading group at the ILLC, bringing together formal semanticists and computational linguists working at our institute to discuss the use of Artificial Neural Networks in modelling human language learning and processing. Below is an archive of the papers we read.</p>
<p>Feel free to keep suggesting papers in our <a href="https://docs.google.com/spreadsheets/d/1h_HJATlutSkfDKYTtoR3zvnCFhUsmhfi1VF-QfodK7w/edit?usp=sharing">sheet</a>!</p>
<h4 id="april-3rd-2023">April 3rd, 2023</h4>
<p>Li, J., Yu, L., &amp; Ettinger, A. (2022). Counterfactual reasoning: Do language models need world knowledge for causal inference? In <em>NeurIPS 2022 Workshop on Neuro Causal and Symbolic AI (nCSI)</em>. <a href="https://arxiv.org/pdf/2212.03278.pdf">https://arxiv.org/pdf/2212.03278.pdf</a></p>
<p><em>presented by:</em> Tom<br>
<em>time:</em> 11-12am CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="march-27th-2023">March 27th, 2023</h4>
<p>Piantadosi, S. (2023). Modern language models refute Chomsky&rsquo;s approach to language. <em>LingBuzz</em>. <a href="https://lingbuzz.net/lingbuzz/007180">https://lingbuzz.net/lingbuzz/007180</a></p>
<p><em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, <strong>L6.27</strong></p>
<h4 id="march-20th-2023">March 20th, 2023</h4>
<p>Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U., &amp; Levy, O. (2020). Emergent linguistic structure in artificial neural networks trained by self-supervision. <em>Proceedings of the National Academy of Sciences, 117</em>(48), 30046-30054. <a href="https://doi.org/10.1073/pnas.1907367117">https://doi.org/10.1073/pnas.1907367117</a></p>
<p><em>presented by:</em> Samuel<br>
<em>time:</em> 2-3pm CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="march-13th-2023">March 13th, 2023</h4>
<p>Merrill, W., Warstadt, A., &amp; Linzen, T. (2022). Entailment Semantics Can Be Extracted from an Ideal Language Model. In <em>Proceedings of the 26th Conference on Computational Natural Language Learning (CoNLL)</em>, pages 176–193, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. <a href="https://aclanthology.org/2022.conll-1.13/">https://aclanthology.org/2022.conll-1.13/</a></p>
<p><em>presented by:</em> Taka<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="march-6th-2023">March 6th, 2023</h4>
<p>McClelland, J. L., Hill, F., Rudolph, M., Baldridge, J., &amp; Schütze, H. (2020). Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models. <em>Proceedings of the National Academy of Sciences, 117</em>(42), 25966-25974. <a href="https://doi.org/10.1073/pnas.1910416117">https://doi.org/10.1073/pnas.1910416117</a></p>
<p><em>presented by:</em> Marianne<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="february-27th-2023">February 27th, 2023</h4>
<p>Jain, S., Vo, V. A., Wehbe, L., &amp; Huth, A. G. (2023). Computational language modeling and the promise of in silico experimentation. <em>Neurobiology of Language</em>, 1-65. <a href="https://doi.org/10.1162/nol_a_00101">https://doi.org/10.1162/nol_a_00101</a></p>
<p><em>presented by:</em> Tamar<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="february-21st-2023">February 21st, 2023</h4>
<p>Andrew K Lampinen, Ishita Dasgupta, Stephanie CY Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L McClelland, Jane X Wang, and Felix Hill. Can language models learn from explanations in context? arXiv preprint arXiv:2204.02329, 2022. <a href="https://arxiv.org/abs/2204.02329">https://arxiv.org/abs/2204.02329</a></p>
<p><em>presented by:</em> Taka<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, <strong>L3.06</strong></p>
<h4 id="february-13th-2023">February 13th, 2023</h4>
<p>Lakretz, Y., Desbordes, T., Hupkes, D., &amp; Dehaene, S. (2022, October). Can Transformers Process Recursive Nested Constructions, Like Humans?. In <em>Proceedings of the 29th International Conference on Computational Linguistics</em> (pp. 3226-3232). <a href="https://aclanthology.org/2022.coling-1.285/">https://aclanthology.org/2022.coling-1.285/</a></p>
<p><em>presented by:</em> Tom<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="february-6th-2023">February 6th, 2023</h4>
<p>Mahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., &amp; Fedorenko, E. (2023). Dissociating language and thought in large language models: a cognitive perspective. arXiv preprint arXiv:2301.06627. <a href="https://arxiv.org/abs/2301.06627">https://arxiv.org/abs/2301.06627</a></p>
<p><em>presented by:</em> Marianne<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, L6.51</p>
<h4 id="january-30th-2023">January 30th, 2023</h4>
<p>Warstadt, A., &amp; Bowman, S. R. (2022). What artificial neural networks can tell us about human language acquisition. In <em>Algebraic Structures in Natural Language</em> (pp. 17-60). CRC Press. <a href="https://arxiv.org/abs/2208.07998">https://arxiv.org/abs/2208.07998</a></p>
<p><em>presented by:</em> Tamar<br>
<em>time:</em> 4-5pm CET<br>
<em>location:</em> LAB42, L6.51</p>

</content>

  </main>
  <footer><small>
    Tamar Johnson &amp; Marianne de Heer Kloots :: <b>ANN-HumLang</b> 
    <a href="/workshop/">Workshop</a> /
    
    <a href="/reading-group-archive/">Reading group archive</a> /
    

    
</small></footer>

    
</body>

</html>
